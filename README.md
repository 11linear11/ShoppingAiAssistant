# ğŸ›’ Shopping AI Assistant

An intelligent Persian shopping assistant powered by LangGraph, MCP (Model Context Protocol), and Elasticsearch. Uses EQuIP 3B for generating Elasticsearch DSL queries and multilingual embeddings for semantic search.

## âœ¨ Features

- **Persian Language Support**: Full support for Persian shopping queries
- **Hybrid Search**: Combines BM25 text matching with semantic similarity
- **Smart Ranking**: Value-based product ranking considering brand scores, prices, and discounts
- **Intent Detection**: Understands shopping intents (cheapest, best quality, best value, etc.)
- **Modular Architecture**: Separate MCP servers for each functionality
- **Observability**: Integrated with Logfire for tracing and logging

## ğŸ—ï¸ Architecture

The system uses a distributed MCP (Model Context Protocol) architecture:

### MCP Servers

| Server | Port | Description |
|--------|------|-------------|
| **embedding-server** | 5003 | Generates multilingual embeddings using intfloat/multilingual-e5-base |
| **interpret-server** | 5004 | Interprets Persian queries, extracts intent, translates to English |
| **equip-server** | 5005 | Generates Elasticsearch DSL using EQuIP 3B model |
| **dsl-processor-server** | 5006 | Transforms English DSL to Persian + adds semantic search |
| **search-server** | 5002 | Orchestrates search pipeline and executes ES queries |

### Data Flow

1. **User Query** â†’ Agent receives Persian shopping query
2. **Interpret** â†’ Extracts intent, translates keywords, identifies categories
3. **EQuIP DSL** â†’ Generates Elasticsearch DSL from structured prompt
4. **DSL Processing** â†’ Converts English terms to Persian, adds semantic search
5. **Elasticsearch** â†’ Executes hybrid search (BM25 + vector similarity)
6. **Ranking** â†’ Applies value-based scoring with brand scores
7. **Response** â†’ Returns ranked products to user

## ğŸ“ Project Structure

```
ShoppingAiAssistant/
â”œâ”€â”€ main.py                      # Main entry point
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env                         # Environment configuration
â”œâ”€â”€ BrandScore.json              # Brand reputation scores
â”œâ”€â”€ CategoryW.json               # Category weights
â”œâ”€â”€ full_category_embeddings.json # Pre-computed category embeddings
â”œâ”€â”€ test_mcp_servers.py          # Server testing script
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent.py                 # LangGraph agent implementation
â”‚   â”œâ”€â”€ logging_config.py        # Centralized Logfire configuration
â”‚   â””â”€â”€ mcp_servers/
â”‚       â”œâ”€â”€ run_servers.py       # Server orchestrator
â”‚       â”œâ”€â”€ embedding_server.py  # Embedding generation
â”‚       â”œâ”€â”€ interpret_server.py  # Query interpretation
â”‚       â”œâ”€â”€ equip_server.py      # DSL generation
â”‚       â”œâ”€â”€ dsl_processor_server.py # DSL transformation
â”‚       â””â”€â”€ search_server.py     # Search orchestration
â”œâ”€â”€ script/                      # Utility scripts
â”œâ”€â”€ config/                      # Configuration files
â””â”€â”€ logs/                        # Server logs
```

## ğŸ“‹ Prerequisites

- Python 3.11+
- Elasticsearch 8.x with shopping products index
- Ollama (for running EQuIP 3B model)
- GROQ API key (for LLM agent)

## ğŸš€ Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/11linear11/ShoppingAiAssistant.git
   cd ShoppingAiAssistant
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment** - Create a .env file with your settings

## âš™ï¸ Configuration

Create a .env file:

```env
# Debug mode
DEBUG_MODE=true

# Elasticsearch
ELASTICSEARCH_HOST=your_elasticsearch_host
ELASTICSEARCH_PORT=9201
ELASTICSEARCH_INDEX=shopping_products

# EQuIP Model (Ollama via Cloudflare tunnel or local)
EQUIP_BASE_URL=https://your-tunnel.trycloudflare.com
EQUIP_MODEL=EQuIP/EQuIP_3B

# LLM for Agent
GROQ_API_KEY=your_groq_api_key

# Logfire (optional)
LOGFIRE_TOKEN=your_logfire_token
```

## ğŸ¯ Usage

### Start all MCP servers

```bash
python src/mcp_servers/run_servers.py
```

### Run the agent

```bash
python main.py
```

### Test servers

```bash
python test_mcp_servers.py           # All servers
python test_mcp_servers.py pipeline  # Full pipeline test
python test_mcp_servers.py interpret # Interpret server only
```

## ğŸ”§ API Reference

### interpret_query

Analyzes user shopping query and returns structured data.

**Input:** Persian shopping query
**Output:**
- equip_prompt: Structured prompt for DSL generation
- token_mapping: English to Persian word mappings
- persian_full_query: Full Persian product description
- categories_fa: Relevant Persian category names
- intent: Shopping intent (find_cheapest, find_best_value, etc.)
- price_sensitivity: 0-1 score
- quality_sensitivity: 0-1 score

### search_with_interpretation

Searches products using interpretation results.

**Input:** All outputs from interpret_query
**Output:** Ranked products with scores

## ğŸ“Š Shopping Intents

| Intent | Description |
|--------|-------------|
| find_cheapest | User wants the lowest price |
| find_best_value | Balance between price and quality |
| find_high_quality | User prioritizes quality over price |
| find_by_feature | Searching for specific features |
| compare | Comparing multiple products |

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ‘¤ Author

Created by [11linear11](https://github.com/11linear11)
