# Shopping AI Assistant ğŸ›ï¸

A conversational AI shopping assistant that uses **LangGraph**, **Elasticsearch**, and **multilingual semantic search** to help users find products naturally.

## Features âœ¨

- **Semantic Search**: Uses `intfloat/multilingual-e5-base` model for understanding queries in multiple languages (including Persian/Farsi)
- **Elasticsearch Integration**: Fast and scalable vector search capabilities
- **Conversational AI**: LangGraph-based agent with conversation memory
- **Tool Integration**: Automatically decides when to search for products based on user intent
- **JSON Output**: Returns product results in structured JSON format
- **Multilingual Support**: Works with English, Persian, and other languages

## Architecture ğŸ—ï¸

```
User Query â†’ LangGraph Agent â†’ LLM â†’ Tool Selection â†’ Elasticsearch Search
                â†“                                              â†“
         Conversation Memory â† JSON Response â† Semantic Embedding
```

## Project Structure ğŸ“

```
ShoppingAiAssistant/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ agent.py           # LangGraph agent implementation
â”‚   â”œâ”€â”€ tools/             # Tools package
â”‚   â”‚   â”œâ”€â”€ SearchProducts.py  # Elasticsearch search tool
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ tests/                  # Test files
â”‚   â””â”€â”€ test_json_output.py
â”œâ”€â”€ examples/               # Usage examples
â”‚   â”œâ”€â”€ basic_usage.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ config/                 # Configuration files
â”‚   â””â”€â”€ .env.example       # Environment variables template
â”œâ”€â”€ script/                 # Utility scripts
â”œâ”€â”€ main.py                # Main entry point
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # Environment variables (create from .env.example)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Installation ğŸš€

1. **Clone the repository**:
```bash
git clone https://github.com/11linear11/ShoppingAiAssistant.git
cd ShoppingAiAssistant
```

2. **Create virtual environment**:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**:
```bash
pip install -r requirements.txt
```

4. **Configure environment variables**:
```bash
cp config/.env.example .env
# Edit .env and add your API keys
```

## Configuration âš™ï¸

Edit `.env` file with your credentials:

```env
# NVIDIA AI Endpoints
api_key=your_nvidia_api_key_here
BASE_URL=https://integrate.api.nvidia.com/v1
MODEL_NAME=openai/gpt-oss-120b

# Elasticsearch
ELASTICSEARCH_HOST=your_elasticsearch_host
ELASTICSEARCH_PORT=9201
ELASTICSEARCH_USER=elastic
ELASTICSEARCH_PASSWORD=your_password
ELASTICSEARCH_INDEX=shopping_products
ELASTICSEARCH_SCHEME=http
```

## Usage ğŸ’»

### Basic Usage

Run the interactive CLI:

```bash
python main.py
```

Example conversation:
```
User: Ø³Ù„Ø§Ù…
Assistant: {"message": "Ø³Ù„Ø§Ù…! Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ú©Ù…Ú©ØªÙˆÙ† Ú©Ù†Ù…ØŸ"}

User: Ø¯ÙˆØº Ø¢Ø¨Ø¹Ù„ÛŒ Ù…ÛŒØ®ÙˆØ§Ù…
Assistant: {"products": [...]}
```

### Python API

```python
from src.agent import create_agent
from langchain_core.messages import HumanMessage

# Create agent
graph = create_agent()
config = {"configurable": {"thread_id": "session_1"}}

# Send message
state = graph.invoke(
    {"messages": [HumanMessage(content="Ø¯ÙˆØº Ù¾ÛŒØ¯Ø§ Ú©Ù† Ø¨Ø±Ø§Ù…")]},
    config=config
)

# Get response
print(state['messages'][-1].content)
```

### Run Tests

```bash
# Test JSON output
python tests/test_json_output.py

# Basic usage example
python examples/basic_usage.py
```

## JSON Response Format ğŸ“‹

### Product Search Response
```json
{
  "products": [
    {
      "name": "Ø¯ÙˆØº Ú¯Ø§Ø²Ø¯Ø§Ø± Ø¢Ø¨Ø¹Ù„ÛŒ Û²Û¶Û° Ù…ÛŒÙ„ÛŒ Ù„ÛŒØªØ±ÛŒ",
      "price": 27500,
      "brand": "Ø¢Ø¨Ø¹Ù„ÛŒ",
      "discount": 15,
      "product_id": "3546253",
      "similarity": 0.872,
      "category": "Ù„Ø¨Ù†ÛŒØ§Øª"
    }
  ]
}
```

### Chat Response
```json
{
  "message": "Ø³Ù„Ø§Ù…! Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ú©Ù…Ú©ØªÙˆÙ† Ú©Ù†Ù…ØŸ"
}
```

## Tech Stack ğŸ› ï¸

- **LangChain & LangGraph**: Agent orchestration and conversation flow
- **NVIDIA AI Endpoints**: LLM inference (gpt-oss-120b)
- **Elasticsearch 9.2.0**: Vector search and product indexing
- **Sentence Transformers**: Multilingual embeddings (intfloat/multilingual-e5-base)
- **Python 3.13**: Runtime environment

## Key Components ğŸ”‘

### Agent (src/agent.py)
- LangGraph-based conversational agent
- Automatic tool calling
- JSON response node for direct output
- Memory persistence with MemorySaver

### Search Tool (src/tools/SearchProducts.py)
- Elasticsearch semantic search
- Cosine similarity scoring
- Multilingual support
- JSON formatted output

## Development ğŸ”§

### Adding New Tools

1. Create tool in `src/tools/`
2. Decorate with `@tool`
3. Import in `src/agent.py`
4. Add to tools list

### Cleaning Up

```bash
# Remove cache files
find . -type d -name __pycache__ -exec rm -rf {} +
find . -type f -name "*.pyc" -delete

# Remove backup files
rm -f *_old.py *.backup
```

## Troubleshooting ğŸ›

### Import Errors
Make sure you're running from the project root:
```bash
cd ShoppingAiAssistant
python main.py
```

### Elasticsearch Connection
Check your Elasticsearch credentials in `.env` file.

### Token Limit Issues
The agent uses a `json_response` node to bypass LLM token limits for product results.

## Contributing ğŸ¤

Contributions are welcome! Please feel free to submit a Pull Request.

## License ğŸ“„

This project is licensed under the MIT License.

## Author âœï¸

11linear11

## Acknowledgments ğŸ™

- LangChain team for the amazing framework
- Elasticsearch for powerful search capabilities
- HuggingFace for multilingual embeddings
