# =============================================================================
# Shopping AI Assistant - Environment Example
# =============================================================================
# Copy this file to .env and set real values:
#   cp .env.example .env
# =============================================================================

# -----------------------------
# App / Backend
# -----------------------------
APP_NAME=Shopping AI Assistant
APP_VERSION=1.0.0
HOST=0.0.0.0
PORT=8080
CORS_ORIGINS=["http://localhost:3000","http://127.0.0.1:3000"]
DEBUG=false
DEBUG_MODE=false
DEBUG_LOG=false

# -----------------------------
# Docker host port mapping (optional)
# Keep internal service ports unchanged; only host bindings change.
# -----------------------------
FRONTEND_HOST_PORT=3000
BACKEND_HOST_PORT=8080
MCP_SEARCH_HOST_PORT=5002
MCP_EMBEDDING_HOST_PORT=5003
MCP_INTERPRET_HOST_PORT=5004
REDIS_HOST_PORT=6379

# -----------------------------
# Agent model selection
# -----------------------------
# Allowed: openrouter | groq
AGENT_MODEL_PROVIDER=openrouter
# Optional override model for selected provider
AGENT_MODEL=
AGENT_TIMEOUT=120

# -----------------------------
# OpenRouter / Groq
# -----------------------------
OPEN_ROUTERS_API_KEY=your_openrouter_api_key
OPENROUTER_MODEL=qwen/qwen-2.5-72b-instruct
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

GROQ_API_KEY=your_groq_api_key
GROQ_MODEL=llama-3.3-70b-versatile
GROQ_BASE_URL=https://api.groq.com/openai/v1

# -----------------------------
# GitHub Models (interpret/search)
# -----------------------------
GITHUB_TOKEN=your_github_token
GITHUB_BASE_URL=https://models.inference.ai.azure.com
GITHUB_MODEL=Llama-3.3-70B-Instruct

# Optional provider/API keys (if you use them)
OPENAI_API_KEY=your_openai_or_github_models_key
NVIDIA_API_KEY=your_nvidia_api_key
NVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1
NVIDIA_MODEL=meta/llama-3.1-70b-instruct
HUGGINGFACEHUB_API_TOKEN=your_hf_token
HF_TOKEN=your_hf_token
CEREBRAS_API_KEY=your_cerebras_api_key

# -----------------------------
# Data stores
# -----------------------------
ELASTICSEARCH_HOST=127.0.0.1
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_SCHEME=http
ELASTICSEARCH_USER=elastic
ELASTICSEARCH_PASSWORD=your_elasticsearch_password
ELASTICSEARCH_INDEX=shopping_products

REDIS_HOST=127.0.0.1
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# -----------------------------
# MCP server URLs
# -----------------------------
MCP_INTERPRET_URL=http://127.0.0.1:5004
MCP_SEARCH_URL=http://127.0.0.1:5002
MCP_EMBEDDING_URL=http://127.0.0.1:5003

# -----------------------------
# Logging / Pipeline tracing
# -----------------------------
PIPELINE_SERVICE_NAME=shopping-assistant
PIPELINE_LOG_DIR=logs
PIPELINE_LOG_TO_FILE=true

USE_LOGFIRE=false
LOGFIRE_TOKEN=your_logfire_token
LOGFIRE_SERVICE_NAME=assistantv3
LOGFIRE_ENVIRONMENT=production

# -----------------------------
# Session / Cache
# -----------------------------
SESSION_TTL_ACTIVE=3600
SESSION_TTL_INACTIVE=86400

AGENT_CACHE_ENABLED=true
AGENT_CACHE_TTL=86400
LLM_CACHE_TTL=86400

CACHE_SEARCH_TTL=3600
CACHE_SEMANTIC_TTL=21600
CACHE_COMPONENT_TTL=86400
CACHE_EMBEDDING_TTL=604800
CACHE_ABSTRACT_TTL=2592000
CACHE_NEGATIVE_TTL=3600

# -----------------------------
# Feature Flags (rollout-safe toggles)
# -----------------------------
FF_INTERPRET_WARMUP=true
FF_INTENT_NORMALIZATION=true
FF_CATEGORY_EMBED_CACHE=true
CATEGORY_MATCH_CACHE_TTL=21600
CATEGORY_MATCH_CACHE_MAX_SIZE=5000
FF_ROUTER_ENABLED=true
FF_ABSTRACT_FASTPATH=true
FF_DIRECT_FASTPATH=false
FF_CONDITIONAL_FINAL_LLM=true
ROUTER_GUARD_T1=0.55
ROUTER_GUARD_T2=0.08
ROUTER_GUARD_MIN_CONFIDENCE=0.58

# -----------------------------
# Search tuning
# -----------------------------
SEARCH_TIMEOUT=30
SEARCH_SIZE=50
RESULT_LIMIT=10
USE_SEMANTIC_SEARCH=false

# -----------------------------
# Embedding server
# -----------------------------
EMBEDDING_MODEL=intfloat/multilingual-e5-base
EMBEDDING_DEVICE=cpu
EMBEDDING_MAX_SEQ_LENGTH=512
EMBEDDING_BATCH_SIZE=32
