"""
Product Search Tool using Elasticsearch and Multilingual Embeddings
This module provides semantic search functionality for products.
"""

import os
import json
import re
import logging
from typing import List, Dict
from statistics import median
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from elasticsearch import Elasticsearch
from langchain_core.tools import tool
from langchain_nvidia_ai_endpoints import ChatNVIDIA
from langchain_openai import ChatOpenAI


load_dotenv()

# Setup logging
DEBUG_MODE = os.getenv("DEBUG_MODE", "false").lower() == "true"
logger = logging.getLogger(__name__)


class ProductSearchEngine:
    """Elasticsearch-based product search with semantic embeddings."""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ProductSearchEngine, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if ProductSearchEngine._initialized:
            return
        
        logger.info("ğŸ”§ Initializing ProductSearchEngine...")
        
        # Load model silently
        model_name = 'intfloat/multilingual-e5-base'
        logger.debug(f"ğŸ“¦ Loading embedding model: {model_name}")
        self.model = SentenceTransformer(model_name)
        logger.debug("âœ… Embedding model loaded")
        
        # Elasticsearch configuration
        ES_HOST = os.getenv("ELASTICSEARCH_HOST", "localhost")
        ES_PORT = os.getenv("ELASTICSEARCH_PORT", "9200")
        ES_USERNAME = os.getenv("ELASTICSEARCH_USER")
        ES_PASSWORD = os.getenv("ELASTICSEARCH_PASSWORD")
        scheme = os.getenv("ELASTICSEARCH_SCHEME", "http")
        
        es_url = f"{scheme}://{ES_HOST}:{ES_PORT}"
        logger.debug(f"ğŸ”Œ Connecting to Elasticsearch: {es_url}")
        
        # Create Elasticsearch client
        try:
            if ES_USERNAME and ES_PASSWORD:
                self.es = Elasticsearch(es_url, basic_auth=(ES_USERNAME, ES_PASSWORD), verify_certs=False)
            else:
                self.es = Elasticsearch(es_url, verify_certs=False)
        except TypeError:
            # Fallback for older versions
            logger.debug("âš ï¸ Using fallback Elasticsearch connection method")
            host_dict = {"host": ES_HOST, "port": int(ES_PORT), "scheme": scheme}
            if ES_USERNAME and ES_PASSWORD:
                self.es = Elasticsearch([host_dict], http_auth=(ES_USERNAME, ES_PASSWORD), verify_certs=False)
            else:
                self.es = Elasticsearch([host_dict], verify_certs=False)
        
        self.index_name = os.getenv("ELASTICSEARCH_INDEX", "shopping_products")
        logger.debug(f"ğŸ“š Index name: {self.index_name}")
        logger.info("âœ… ProductSearchEngine initialized successfully")
        
        ProductSearchEngine._initialized = True
    
    def search(self, query_text: str, top_k: int = 5, min_similarity: float = 0.3, category: str = None) -> List[Dict]:
        """
        Perform hybrid search combining BM25 text matching and semantic similarity.
        
        Args:
            query_text: Search query
            top_k: Number of results
            min_similarity: Minimum similarity score (0-1)
            category: Optional category filter (e.g., "Ù„Ù¾ ØªØ§Ù¾", "Ú¯ÙˆØ´ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„")
            
        Returns:
            List of product dictionaries sorted by combined relevance score
        """
        logger.info(f"ğŸ” Starting search for: '{query_text}'")
        logger.debug(f"ğŸ“Š Parameters: top_k={top_k}, min_similarity={min_similarity}, category={category}")
        
        # Generate embedding for semantic search
        logger.debug("ğŸ§  Generating query embedding...")
        query_embedding = self.model.encode([query_text])[0].tolist()
        logger.debug(f"âœ… Embedding generated (dim={len(query_embedding)})")
        
        # Build query with BM25 + embedding hybrid search
        must_conditions = []
        
        # Add category filter if provided
        if category:
            must_conditions.append({"match": {"category_name": category}})
            logger.debug(f"ğŸ·ï¸ Category filter applied: {category}")
        
        # Hybrid search: BM25 (text) + semantic (embedding)
        search_body = {
            "size": 50, 
            "query": {
                "bool": {
                    "must": must_conditions if must_conditions else [{"match_all": {}}],
                    "should": [
                        # BM25 text search on product name and brand
                        {
                            "multi_match": {
                                "query": query_text,
                                "fields": ["product_name^2", "brand_name", "category_name"],
                                "type": "best_fields",
                                "boost": 1.0
                            }
                        },
                        # Semantic similarity search
                        {
                            "script_score": {
                                "query": {"match_all": {}},
                                "script": {
                                    "source": "cosineSimilarity(params.query_vector, 'product_embedding') + 1.0",
                                    "params": {"query_vector": query_embedding}
                                },
                                "boost": 2.0
                            }
                        }
                    ],
                    "minimum_should_match": 1
                }
            }
        }
        
        try:
            logger.debug("ğŸ“¡ Executing Elasticsearch query...")
            response = self.es.search(index=self.index_name, body=search_body)
            logger.debug(f"âœ… Elasticsearch response received: {response['hits']['total']['value']} total hits")
            
            results = []
            
            for hit in response['hits']['hits']:
                source = hit['_source']
                score = hit['_score']
                
                # Calculate semantic similarity from embedding
                # Note: exact similarity needs recalculation, using score as proxy
                similarity = min(1.0, score / 3.0)  # Normalize combined score
                
                results.append({
                    'product_id': source.get('product_id', ''),
                    'product_name': source.get('product_name', ''),
                    'brand_name': source.get('brand_name', ''),
                    'price': source.get('price', 0),
                    'discount_price': source.get('discount_price', 0),
                    'category_name': source.get('category_name', ''),
                    'has_discount': source.get('has_discount', False),
                    'discount_percentage': source.get('discount_percentage', 0),
                    'similarity': similarity,
                    'score': score
                })
            
            logger.debug(f"ğŸ“¦ Collected {len(results)} raw results")
            
            # Dynamic filtering based on similarity distribution
            if results:
                similarities = [r['similarity'] for r in results]
                dyn_thresh = max(0.38, median(similarities) - 0.15)
                filtered = [r for r in results if r['similarity'] >= dyn_thresh]
                logger.info(f"ğŸ” Dynamic filter: threshold={dyn_thresh:.3f}, kept {len(filtered)}/{len(results)} results")
            else:
                filtered = []
                logger.warning("âš ï¸ No results found")
            
            logger.info(f"âœ… Search completed: returning {len(filtered)} products")
            return filtered
            
        except Exception as e:
            logger.error(f"âŒ Elasticsearch error: {str(e)}")
            return []

# Global LLM instance for interpret_query
_llm_instance = None


def get_llm_instance():
    """Get or create a cached LLM instance for query interpretation."""
    global _llm_instance
    if _llm_instance is None:
        # Try different NVIDIA models - some may be unavailable or return empty responses
        nvidia_models = [
            "meta/llama-3.1-70b-instruct",  # More stable model
            "meta/llama-3.1-8b-instruct",   # Lighter fallback
            "openai/gpt-oss-120b",          # Original model
        ]
        
        model = os.getenv("NVIDIA_MODEL", nvidia_models[0])
        logger.info(f"ğŸ¤– Using NVIDIA model: {model}")
        
        _llm_instance = ChatNVIDIA(
            model=model,
            api_key=os.getenv("api_key"),
            base_url="https://integrate.api.nvidia.com/v1",   
            temperature=0.1,
            max_tokens=1000
        )
        # Alternative: OpenAI
        # _llm_instance = ChatOpenAI(
        #     model="openai/gpt-4o",
        #     api_key = os.getenv("OPENAI_API_KEY"),
        #     base_url = "https://models.inference.ai.azure.com",   
        # )
        
    return _llm_instance


@tool
def interpret_query(query: str) -> str:
    """
    Analyze user shopping intent and extract structured information.
    
    This tool helps understand what the user is looking for by analyzing their query
    and returning key insights about their shopping preferences and intent.
    
    Args:
        query: User's shopping query in natural language (Persian, English, or other languages)
        
    Returns:
        JSON string with the following fields:
        - category: Product category (e.g., "Ù„Ù¾ ØªØ§Ù¾", "Ú¯ÙˆØ´ÛŒ", "Ù‡Ø¯ÙÙˆÙ†")
        - intent: Shopping intent (find_cheapest, find_best_value, find_high_quality, compare, find_by_feature)
        - price_sensitivity: 0-1 (higher = more price-conscious)
        - quality_sensitivity: 0-1 (higher = more quality-focused)
        - suggested_query: A specific product keyword to search for
    """
    
    # Available categories in Elasticsearch
    AVAILABLE_CATEGORIES = [
        "Ù„ÙˆØ§Ø²Ù… Ø§Ù„Ú©ØªØ±ÙˆÙ†ÛŒÚ©ÛŒ",
        "Ù„ÙˆØ§Ø²Ù… Ø¨Ø±Ù‚ÛŒ Ùˆ Ø¯ÛŒØ¬ÛŒØªØ§Ù„",
        "Ù…Ø¯ Ùˆ Ù¾ÙˆØ´Ø§Ú©",
        "Ø·Ù„Ø§",
        "Ø®Ø§Ù†Ù‡ Ùˆ Ø³Ø¨Ú© Ø²Ù†Ø¯Ú¯ÛŒ",
        "Ø®Ø§Ù†Ù‡ Ùˆ Ø¢Ø´Ù¾Ø²Ø®Ø§Ù†Ù‡",
        "Ø¢Ø±Ø§ÛŒØ´ÛŒ Ùˆ Ø¨Ù‡Ø¯Ø§Ø´ØªÛŒ",
        "Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ",
        "Ù„Ø¨Ù†ÛŒØ§Øª",
        "Ú©Ø§Ù„Ø§Ù‡Ø§ÛŒ Ø§Ø³Ø§Ø³ÛŒ",
        "Ú©ÙˆØ¯Ú© Ùˆ Ù†ÙˆØ²Ø§Ø¯",
        "Ø®ÙˆØ§Ø±Ø¨Ø§Ø± Ùˆ Ù†Ø§Ù†",
        "Ø¨Ù‡Ø¯Ø§Ø´Øª Ùˆ Ø³Ù„Ø§Ù…Øª",
        "Ø´ÙˆÛŒÙ†Ø¯Ù‡ Ùˆ Ù…ÙˆØ§Ø¯ Ø¶Ø¯ Ø¹ÙÙˆÙ†ÛŒ Ú©Ù†Ù†Ø¯Ù‡",
        "Ù…ÙˆØ§Ø¯ Ù¾Ø±ÙˆØªØ¦ÛŒÙ†ÛŒ",
        "Ù…ÛŒÙˆÙ‡ Ùˆ Ø³Ø¨Ø²ÛŒØ¬Ø§Øª ØªØ§Ø²Ù‡",
        "Ø¯Ø³ØªÙ…Ø§Ù„ Ùˆ Ø´ÙˆÛŒÙ†Ø¯Ù‡",
        "Ù…Ø­ØµÙˆÙ„Ø§Øª Ø³Ù„ÙˆÙ„Ø²ÛŒ",
        "Ú†Ø§Ø´Ù†ÛŒ Ùˆ Ø§ÙØ²ÙˆØ¯Ù†ÛŒ",
        "ØªÙ†Ù‚Ù„Ø§Øª",
        "Ú©Ù†Ø³Ø±Ùˆ Ùˆ ØºØ°Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡",
        "ØµØ¨Ø­Ø§Ù†Ù‡",
        "Ú©Ù†Ø³Ø±Ùˆ Ùˆ ØºØ°Ø§Ù‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡",
        "Ø¢Ø¬ÛŒÙ„ Ùˆ Ø®Ø´Ú©Ø¨Ø§Ø±",
        "Ø®Ø´Ú©Ø¨Ø§Ø±ØŒ Ø¯Ø³Ø± Ùˆ Ø´ÛŒØ±ÛŒÙ†ÛŒ",
        "Ù„ÙˆØ§Ø²Ù… ØªØ­Ø±ÛŒØ± Ùˆ Ø§Ø¯Ø§Ø±ÛŒ",
        "Ø¯Ø³Ø± Ùˆ Ø´ÛŒØ±ÛŒÙ†ÛŒ Ù¾Ø²ÛŒ",
        "Ù†Ø§Ù† Ùˆ Ø´ÛŒØ±ÛŒÙ†ÛŒ"
    ]
    
    # Construct a clear, structured prompt
    prompt =   f"""
You are a purchase-intent interpreter. Your job is to convert each user message into structured data that can be used by the product search engine.

Your output must be exactly one valid JSON object. Produce no additional text.

-----------------------------------------------
ğŸ“‹ Available categories in the system:
{AVAILABLE_CATEGORIES}

-----------------------------------------------
Important Rules:

1. **CATEGORY Detection:**

   a) If the user mentions a *specific product*:
   - "Ø´ÙˆØ±Øª", "ØªÛŒØ´Ø±Øª", "Ú©ÙØ´" â†’ "Ù…Ø¯ Ùˆ Ù¾ÙˆØ´Ø§Ú©"
   - "Ø¯ÙˆØº", "Ø¢Ø¨Ù…ÛŒÙˆÙ‡", "Ù†ÙˆØ´Ø§Ø¨Ù‡" â†’ "Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ"
   - "Ù…Ø§Ø³Øª", "Ù¾Ù†ÛŒØ±", "Ø´ÛŒØ±" â†’ "Ù„Ø¨Ù†ÛŒØ§Øª"
   - "Ù„Ù¾ ØªØ§Ù¾", "Ú¯ÙˆØ´ÛŒ", "Ù‡Ø¯ÙÙˆÙ†" â†’ "Ù„ÙˆØ§Ø²Ù… Ø§Ù„Ú©ØªØ±ÙˆÙ†ÛŒÚ©ÛŒ"
   - "Ø´Ø§Ù…Ù¾Ùˆ", "Ú©Ø±Ù…", "Ø±Ú˜Ù„Ø¨" â†’ "Ø¢Ø±Ø§ÛŒØ´ÛŒ Ùˆ Ø¨Ù‡Ø¯Ø§Ø´ØªÛŒ"
   - "Ù…Ø§ÛŒØ¹ Ø¸Ø±ÙØ´ÙˆÛŒÛŒ", "Ù¾ÙˆØ¯Ø± Ù„Ø¨Ø§Ø³Ø´ÙˆÛŒÛŒ" â†’ "Ø´ÙˆÛŒÙ†Ø¯Ù‡ Ùˆ Ù…ÙˆØ§Ø¯ Ø¶Ø¯ Ø¹ÙÙˆÙ†ÛŒ Ú©Ù†Ù†Ø¯Ù‡"
   - "Ú†ÛŒÙ¾Ø³", "Ø´Ú©Ù„Ø§Øª", "Ù¾ÙÚ©" â†’ "ØªÙ†Ù‚Ù„Ø§Øª"

   b) If the user only gives *abstract properties*:
   - "Ù†Ø±Ù…", "Ù„Ø·ÛŒÙ", "Ø±Ø§Ø­Øª" â†’ likely "Ù…Ø¯ Ùˆ Ù¾ÙˆØ´Ø§Ú©" or "Ø¯Ø³ØªÙ…Ø§Ù„ Ùˆ Ø´ÙˆÛŒÙ†Ø¯Ù‡"
   - "ØªØ±Ø¯", "Ø®ÙˆØ´Ù…Ø²Ù‡" â†’ likely "ØªÙ†Ù‚Ù„Ø§Øª"
   - "ØªÙ†Ø¯", "ÙÙ„ÙÙ„ÛŒ", "ØªÛŒØ²" â†’ likely "ØªÙ†Ù‚Ù„Ø§Øª" or "Ú†Ø§Ø´Ù†ÛŒ Ùˆ Ø§ÙØ²ÙˆØ¯Ù†ÛŒ"
   - "Ø®Ù†Ú©", "Ø®ÙˆØ´Ø¨Ùˆ" (for liquids) â†’ likely "Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ" or "Ø¢Ø±Ø§ÛŒØ´ÛŒ Ùˆ Ø¨Ù‡Ø¯Ø§Ø´ØªÛŒ"
   - "Ø®ÙˆØ´Ø¨Ùˆ" (cleaning items) â†’ likely "Ø´ÙˆÛŒÙ†Ø¯Ù‡ Ùˆ Ù…ÙˆØ§Ø¯ Ø¶Ø¯ Ø¹ÙÙˆÙ†ÛŒ Ú©Ù†Ù†Ø¯Ù‡"
   - "ØªØ§Ø²Ù‡" â†’ likely "Ù…ÛŒÙˆÙ‡ Ùˆ Ø³Ø¨Ø²ÛŒØ¬Ø§Øª ØªØ§Ø²Ù‡" or "Ù„Ø¨Ù†ÛŒØ§Øª" or "Ù†Ø§Ù† Ùˆ Ø´ÛŒØ±ÛŒÙ†ÛŒ"

   c) **Important rule:** you must ALWAYS guess a category!  
      Only return null if the message is completely unrelated to buying.
      - If the user mentions a taste (ØªÙ†Ø¯, Ø´ÛŒØ±ÛŒÙ†, ØªØ±Ø´) â†’ "ØªÙ†Ù‚Ù„Ø§Øª" or "Ú†Ø§Ø´Ù†ÛŒ Ùˆ Ø§ÙØ²ÙˆØ¯Ù†ÛŒ"
      - If the user mentions a physical feel (Ù†Ø±Ù…, Ø³Ø¨Ú©) â†’ "Ù…Ø¯ Ùˆ Ù¾ÙˆØ´Ø§Ú©"

2. **intent** must be one of the following (never return null!):
   - find_cheapest        â†’ user wants the cheapest option
   - find_best_value      â†’ user wants best price/quality ratio
   - find_high_quality    â†’ user prioritizes quality
   - compare              â†’ user wants to compare options
   - find_by_feature      â†’ user mentions a specific feature (size, softness, flavor, etc.)

3. **price_sensitivity:**
   - 1.0 â†’ words like "Ø§Ø±Ø²ÙˆÙ†", "Ø§Ø±Ø²Ø§Ù†â€ŒØªØ±ÛŒÙ†", "Ù…Ù‚Ø±ÙˆÙ†â€ŒØ¨Ù‡â€ŒØµØ±ÙÙ‡", "Ø§Ù‚ØªØµØ§Ø¯ÛŒ"
   - 0.5 â†’ indirect or unclear mention of cost
   - 0   â†’ no price-related mention

4. **quality_sensitivity:**
   - 1.0 â†’ words like "Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§", "Ù…Ø­Ú©Ù…", "Ø¯ÙˆØ§Ù…", "Ù¾Ø±ÙÙˆØ±Ù…Ù†Ø³ Ø¨Ø§Ù„Ø§", "Ù†Ø±Ù…", "Ù„Ø·ÛŒÙ"
   - 0.5 â†’ unclear or partial quality mention
   - 0   â†’ no quality mention

5. **suggested_query (Ù…Ù‡Ù…!):**
   Ø§ÛŒÙ† ÙÛŒÙ„Ø¯ Ø¨Ø§ÛŒØ¯ ÛŒÚ© Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø´Ø®Øµ Ù…Ø­ØµÙˆÙ„ Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø´Ù‡.
   
   Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù…Ø­ØµÙˆÙ„ Ù…Ø´Ø®Øµ Ú¯ÙØª â†’ Ù‡Ù…ÙˆÙ† Ù…Ø­ØµÙˆÙ„
   Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù…Ø¨Ù‡Ù… ØµØ­Ø¨Øª Ú©Ø±Ø¯ â†’ ÛŒÚ© Ù…Ø­ØµÙˆÙ„ Ù…Ù†Ø§Ø³Ø¨ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø¯Ù‡
   
   Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§:
   - "ÛŒÚ†ÛŒØ² Ù…ÛŒØ®ÙˆØ§Ù… Ø¨Ù¾ÙˆØ´Ù… Ø³Ø±Ø¯Ù… Ù†Ø´Ù‡" â†’ suggested_query: "Ú©Ø§Ù¾Ø´Ù†"
   - "Ú¯Ø´Ù†Ù…Ù‡" â†’ suggested_query: "Ø¨ÛŒØ³Ú©ÙˆÛŒØª"
   - "ØªØ´Ù†Ù…Ù‡" â†’ suggested_query: "Ø¢Ø¨ Ù…Ø¹Ø¯Ù†ÛŒ"
   - "Ù…ÛŒØ®ÙˆØ§Ù… Ù…ÙˆÙ‡Ø§Ù…Ùˆ Ø¨Ø´ÙˆØ±Ù…" â†’ suggested_query: "Ø´Ø§Ù…Ù¾Ùˆ"
   - "Ù¾ÙˆØ³ØªÙ… Ø®Ø´Ú©Ù‡" â†’ suggested_query: "Ú©Ø±Ù… Ù…Ø±Ø·ÙˆØ¨ Ú©Ù†Ù†Ø¯Ù‡"
   - "ÛŒÚ†ÛŒØ² ØªÙ†Ø¯ Ù…ÛŒØ®ÙˆØ§Ù…" â†’ suggested_query: "Ú†ÛŒÙ¾Ø³ ØªÙ†Ø¯"
   - "ÛŒÚ†ÛŒØ² Ø´ÛŒØ±ÛŒÙ† Ù…ÛŒØ®ÙˆØ§Ù…" â†’ suggested_query: "Ø´Ú©Ù„Ø§Øª"
   - "Ù…ÛŒØ®ÙˆØ§Ù… ÛŒÙ‡ Ú†ÛŒØ² Ú¯Ø±Ù… Ø¨Ø®ÙˆØ±Ù…" â†’ suggested_query: "Ø³ÙˆÙ¾"
   - "Ø®ÙˆØ§Ø¨Ù… Ù…ÛŒØ§Ø¯" â†’ suggested_query: "Ù‚Ù‡ÙˆÙ‡"
   - "Ù‡Ø¯ÙÙˆÙ† Ù…ÛŒØ®ÙˆØ§Ù…" â†’ suggested_query: "Ù‡Ø¯ÙÙˆÙ†"

-----------------------------------------------
### Direct Examples (specific product)

User: "Ø¯ÙˆØº Ø®ÙˆØ´Ù…Ø²Ù‡ Ùˆ Ø§Ø±Ø²ÙˆÙ†"
{{
  "category": "Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ",
  "intent": "find_best_value",
  "price_sensitivity": 1,
  "quality_sensitivity": 1,
  "suggested_query": "Ø¯ÙˆØº"
}}

User: "Ø´ÙˆØ±Øª ÙˆØ±Ø²Ø´ÛŒ Ù†Ø±Ù… Ù…ÛŒâ€ŒØ®ÙˆØ§Ù…"
{{
  "category": "Ù…Ø¯ Ùˆ Ù¾ÙˆØ´Ø§Ú©",
  "intent": "find_by_feature",
  "price_sensitivity": 0,
  "quality_sensitivity": 1,
  "suggested_query": "Ø´ÙˆØ±Øª ÙˆØ±Ø²Ø´ÛŒ"
}}

User: "Ú†ÛŒÙ¾Ø³ Ø³Ø§Ø¯Ù‡ Ø§Ø±Ø²Ø§Ù†"
{{
  "category": "ØªÙ†Ù‚Ù„Ø§Øª",
  "intent": "find_cheapest",
  "price_sensitivity": 1,
  "quality_sensitivity": 0,
  "suggested_query": "Ú†ÛŒÙ¾Ø³"
}}

-----------------------------------------------
### Implicit Intent Examples (user describes need, not product)

User: "ÛŒÚ†ÛŒØ² Ù…ÛŒØ®ÙˆØ§Ù… Ø¨Ù¾ÙˆØ´Ù… Ø³Ø±Ø¯Ù… Ù†Ø´Ù‡"
{{
  "category": "Ù…Ø¯ Ùˆ Ù¾ÙˆØ´Ø§Ú©",
  "intent": "find_by_feature",
  "price_sensitivity": 0.5,
  "quality_sensitivity": 0.5,
  "suggested_query": "Ú©Ø§Ù¾Ø´Ù†"
}}

User: "Ú¯Ø´Ù†Ù…Ù‡ ÛŒÚ†ÛŒØ² Ø¨Ø¯Ù‡"
{{
  "category": "ØªÙ†Ù‚Ù„Ø§Øª",
  "intent": "find_by_feature",
  "price_sensitivity": 0.5,
  "quality_sensitivity": 0.5,
  "suggested_query": "Ø¨ÛŒØ³Ú©ÙˆÛŒØª"
}}

User: "ØªØ´Ù†Ù…Ù‡"
{{
  "category": "Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ",
  "intent": "find_by_feature",
  "price_sensitivity": 0.5,
  "quality_sensitivity": 0.5,
  "suggested_query": "Ø¢Ø¨ Ù…Ø¹Ø¯Ù†ÛŒ"
}}

User: "Ù¾ÙˆØ³ØªÙ… Ø®Ø´Ú©Ù‡"
{{
  "category": "Ø¢Ø±Ø§ÛŒØ´ÛŒ Ùˆ Ø¨Ù‡Ø¯Ø§Ø´ØªÛŒ",
  "intent": "find_by_feature",
  "price_sensitivity": 0.5,
  "quality_sensitivity": 0.5,
  "suggested_query": "Ú©Ø±Ù… Ù…Ø±Ø·ÙˆØ¨ Ú©Ù†Ù†Ø¯Ù‡"
}}

User: "Ø®ÙˆØ§Ø¨Ù… Ù…ÛŒØ§Ø¯ Ø¨Ø§ÛŒØ¯ Ø¨ÛŒØ¯Ø§Ø± Ø¨Ù…ÙˆÙ†Ù…"
{{
  "category": "Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ",
  "intent": "find_by_feature",
  "price_sensitivity": 0.5,
  "quality_sensitivity": 0.5,
  "suggested_query": "Ù‚Ù‡ÙˆÙ‡"
}}

-----------------------------------------------
### Ambiguous Examples (only features)

User: "Ù…Ù† ÛŒÙ‡ Ú†ÛŒØ² ØªÙ†Ø¯ Ù…ÛŒØ®ÙˆØ§Ù…"
{{
  "category": "ØªÙ†Ù‚Ù„Ø§Øª",
  "intent": "find_by_feature",
  "price_sensitivity": 0.5,
  "quality_sensitivity": 0.5,
  "suggested_query": "Ú†ÛŒÙ¾Ø³ ØªÙ†Ø¯"
}}

User: "ÛŒÙ‡ Ú†ÛŒØ² Ù†Ø±Ù…"
{{
  "category": "Ù…Ø¯ Ùˆ Ù¾ÙˆØ´Ø§Ú©",
  "intent": "find_by_feature",
  "price_sensitivity": 0.5,
  "quality_sensitivity": 0.5,
  "suggested_query": "ØªÛŒØ´Ø±Øª"
}}

User: "ÛŒÙ‡ Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ Ø®Ù†Ú©"
{{
  "category": "Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ",
  "intent": "find_by_feature",
  "price_sensitivity": 0.5,
  "quality_sensitivity": 0.5,
  "suggested_query": "Ø¢Ø¨ Ù…Ø¹Ø¯Ù†ÛŒ"
}}

-----------------------------------------------
### Final Rules
- Think step-by-step internally, but do NOT output your reasoning. 
Never include analysis, thoughts, explanations, or chain-of-thought in the output. 
Output only the final JSON.
- You MUST output ONLY one valid JSON object.
If you output anything else (text, explanation, markdown, analysis), it will be considered an error.
- If multiple interpretations exist, choose the most likely one.
- If any feature is mentioned â†’ intent = find_by_feature
- **Always guess a category!**  
- **Always return an intent! Never return null.**
- **Always provide a suggested_query!** This is the keyword for product search.

-----------------------------------------------
User Query: {query}

Your output must match this exact structure:

{{
  "category": "...",
  "intent": "...",
  "price_sensitivity": 0.0,
  "quality_sensitivity": 0.0,
  "suggested_query": "..."
}}

Do not add or remove any fields.
Do not write any text outside this JSON.


"""

    
    logger.info(f"ğŸ§  Interpreting query: '{query}'")
    
    try:
        # Get LLM instance
        logger.debug("ğŸ¤– Getting LLM instance for interpretation...")
        llm = get_llm_instance()
        
        # Invoke LLM
        logger.debug("ğŸ’­ Invoking LLM for intent analysis...")
        response = llm.invoke(prompt)
        
        # Debug: Log the full response object structure
        logger.debug(f"ğŸ“„ Raw response type: {type(response)}")
        logger.debug(f"ğŸ“„ Raw response: {response}")
        
        # Try multiple ways to extract content
        response_text = ""
        if hasattr(response, 'content') and response.content:
            response_text = response.content.strip()
        elif hasattr(response, 'text') and response.text:
            response_text = response.text.strip()
        elif isinstance(response, dict):
            response_text = response.get('content', '') or response.get('text', '') or str(response)
        elif isinstance(response, str):
            response_text = response.strip()
        else:
            # Last resort: convert to string
            response_text = str(response).strip()
        
        logger.debug(f"ğŸ“„ Extracted response_text: '{response_text[:200] if response_text else 'EMPTY'}'")
        
        # Check if response is empty
        if not response_text:
            logger.warning("âš ï¸ LLM returned empty response! Using fallback values.")
            fallback = {
                "category": "Ù†Ø§Ù…Ø´Ø®Øµ",
                "intent": "find_best_value",
                "price_sensitivity": 0.5,
                "quality_sensitivity": 0.5,
                "suggested_query": query,
            }
            return json.dumps(fallback, ensure_ascii=False)
        
        # Extract JSON from response (in case LLM adds extra text)
        json_match = re.search(r'\{[^}]+\}', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            logger.debug("âœ… JSON extracted from response")
        else:
            json_str = response_text
            logger.debug("âš ï¸ Using full response as JSON")
        
        # Validate JSON structure
        try:
            parsed = json.loads(json_str)
            logger.debug(f"âœ… JSON parsed successfully: {parsed}")
            logger.debug(f"ğŸ” Parsed fields: {list(parsed.keys())}")
            
            # Handle null values from JSON (become None in Python)
            category = parsed.get("category")
            intent = parsed.get("intent")
            price_sens = parsed.get("price_sensitivity")
            quality_sens = parsed.get("quality_sensitivity")
            suggested_query = parsed.get("suggested_query")
            
            # Smart defaults for null/None values
            if category is None:
                category = "Ù†Ø§Ù…Ø´Ø®Øµ"
                logger.debug("âš ï¸ Category was null, using 'Ù†Ø§Ù…Ø´Ø®Øµ'")
            
            if intent is None:
                intent = "find_by_feature"  # Default for ambiguous queries
                logger.debug("âš ï¸ Intent was null, using 'find_by_feature'")
            
            if suggested_query is None:
                # Ø§Ú¯Ø± suggested_query Ù†Ø¨ÙˆØ¯ØŒ Ø§Ø² query Ø§ØµÙ„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                suggested_query = query
                logger.debug(f"âš ï¸ suggested_query was null, using original query: '{query}'")
            
            # Ensure required fields exist with defaults
            result = {
                "category": category,
                "intent": intent,
                "price_sensitivity": float(price_sens) if price_sens is not None else 0.5,
                "quality_sensitivity": float(quality_sens) if quality_sens is not None else 0.5,
                "suggested_query": suggested_query,
            }
            
            # Clamp values between 0 and 1
            for key in ["price_sensitivity", "quality_sensitivity"]:
                result[key] = max(0.0, min(1.0, result[key]))
            
            logger.info(f"âœ… Intent analysis complete: category={result['category']}, "
                       f"intent={result['intent']}, "
                       f"suggested_query='{result['suggested_query']}', "
                       f"price_sens={result['price_sensitivity']:.2f}, "
                       f"quality_sens={result['quality_sensitivity']:.2f}")
            
            return json.dumps(result, ensure_ascii=False)
            
        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ JSON decode error: {e}. Using fallback values.")
            # Fallback: return default values
            fallback = {
                "category": "Ù†Ø§Ù…Ø´Ø®Øµ",
                "intent": "find_best_value",
                "price_sensitivity": 0.5,
                "quality_sensitivity": 0.5,
                "suggested_query": query,
            }
            return json.dumps(fallback, ensure_ascii=False)
            
    except Exception as e:
        logger.error(f"âŒ Error in interpret_query: {str(e)}")
        # In case of any error, return safe defaults
        error_response = {
            "category": "Ø®Ø·Ø§",
            "intent": "find_best_value",
            "price_sensitivity": 0.5,
            "quality_sensitivity": 0.5,
            "suggested_query": query,
            "error": str(e)
        }
        return json.dumps(error_response, ensure_ascii=False)








# Global instance
_search_engine = None
_brand_scores = None


def get_search_engine() -> ProductSearchEngine:
    """Get or create the global search engine instance."""
    global _search_engine
    if _search_engine is None:
        _search_engine = ProductSearchEngine()
    return _search_engine


def get_brand_scores() -> Dict[str, float]:
    """Load brand scores from JSON file."""
    global _brand_scores
    if _brand_scores is None:
        try:
            brand_score_path = os.path.join(os.path.dirname(__file__), '../../BrandScore.json')
            with open(brand_score_path, 'r', encoding='utf-8') as f:
                _brand_scores = json.load(f)
        except:
            _brand_scores = {}
    return _brand_scores


@tool
def search_products_semantic(query: str, quality_sensitivity: float = 0.5, price_sensitivity: float = 0.5, category: str = None, intent: str = None) -> str:
    """
    Search for products using semantic search with Elasticsearch and intelligent reranking.
    Use this tool when the user wants to find, search, or look for products.
    This tool understands natural language in multiple languages (English, Persian, Arabic, etc.).
    
    Args:
        query: The product search query in natural language (e.g., "Ù„Ù¾ ØªØ§Ù¾ Ú¯ÛŒÙ…ÛŒÙ†Ú¯", "cheap smartphone", "Ù‡Ø¯ÙÙˆÙ† Ø¨ÛŒ Ø³ÛŒÙ…")
        quality_sensitivity: User's quality preference (0-1), higher means quality matters more
        price_sensitivity: User's price preference (0-1), higher means cheaper is better
        category: Product category filter (e.g., "Ù…Ø¯ Ùˆ Ù¾ÙˆØ´Ø§Ú©", "Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ", "Ù„ÙˆØ§Ø²Ù… Ø§Ù„Ú©ØªØ±ÙˆÙ†ÛŒÚ©ÛŒ")
        intent: User's shopping intent (find_cheapest, find_best_value, find_high_quality, compare, find_by_feature)
        
    Returns:
        JSON string with reranked products based on value score calculation.
    """
    logger.info(f"ğŸ›ï¸ Product search: '{query}'")
    logger.debug(f"âš™ï¸ Sensitivity params: quality={quality_sensitivity:.2f}, price={price_sensitivity:.2f}")
    logger.debug(f"ğŸ¯ Intent: {intent}")
    if category:
        logger.info(f"ğŸ·ï¸ Category filter: '{category}'")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ¯ ØªÙ†Ø¸ÛŒÙ… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ intent
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if intent:
        intent = intent.lower().strip()
        
        if intent == "find_cheapest":
            # Ú©Ø§Ø±Ø¨Ø± Ø§Ø±Ø²Ø§Ù†â€ŒØªØ±ÛŒÙ† Ø±Ùˆ Ù…ÛŒØ®ÙˆØ§Ø¯ - Ù‚ÛŒÙ…Øª Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù…Ù‡ØŒ Ú©ÛŒÙÛŒØª Ù…Ù‡Ù… Ù†ÛŒØ³Øª
            price_sensitivity = max(price_sensitivity, 0.9)
            quality_sensitivity = min(quality_sensitivity, 0.2)
            logger.info("ğŸ’° Intent 'find_cheapest' â†’ Boosting price_sensitivity to 0.9")
            
        elif intent == "find_high_quality":
            # Ú©Ø§Ø±Ø¨Ø± Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ Ù…ÛŒØ®ÙˆØ§Ø¯ - Ø¨Ø±Ù†Ø¯ Ùˆ Ú©ÛŒÙÛŒØª Ù…Ù‡Ù…Ù‡ØŒ Ù‚ÛŒÙ…Øª Ù…Ù‡Ù… Ù†ÛŒØ³Øª
            quality_sensitivity = max(quality_sensitivity, 0.9)
            price_sensitivity = min(price_sensitivity, 0.2)
            logger.info("â­ Intent 'find_high_quality' â†’ Boosting quality_sensitivity to 0.9")
            
        elif intent == "find_best_value":
            # Ú©Ø§Ø±Ø¨Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ø±Ø²Ø´ (Ù†Ø³Ø¨Øª Ú©ÛŒÙÛŒØª Ø¨Ù‡ Ù‚ÛŒÙ…Øª) Ø±Ùˆ Ù…ÛŒØ®ÙˆØ§Ø¯
            price_sensitivity = 0.6
            quality_sensitivity = 0.6
            logger.info("âš–ï¸ Intent 'find_best_value' â†’ Balanced sensitivities (0.6, 0.6)")
            
        elif intent == "compare":
            # Ú©Ø§Ø±Ø¨Ø± Ù…ÛŒØ®ÙˆØ§Ø¯ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ú©Ù†Ù‡ - Ù†ØªØ§ÛŒØ¬ Ù…ØªÙ†ÙˆØ¹â€ŒØªØ± Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ù‡
            price_sensitivity = 0.5
            quality_sensitivity = 0.5
            logger.info("ğŸ”„ Intent 'compare' â†’ Neutral sensitivities for diverse results")
            
        elif intent == "find_by_feature":
            # Ú©Ø§Ø±Ø¨Ø± ÙˆÛŒÚ˜Ú¯ÛŒ Ø®Ø§ØµÛŒ Ù…ÛŒØ®ÙˆØ§Ø¯ - similarity (Ø´Ø¨Ø§Ù‡Øª Ø¨Ù‡ query) Ù…Ù‡Ù…â€ŒØªØ±Ù‡
            logger.info("ğŸ” Intent 'find_by_feature' â†’ Prioritizing similarity score")
    
    try:
        # Get search engine
        logger.debug("ğŸ”§ Getting search engine instance...")
        engine = get_search_engine()
        
        # Perform search with category filter
        logger.debug("ğŸ” Executing search...")
        results = engine.search(query, top_k=100, min_similarity=0.3, category=category)

        if not results:
            logger.warning(f"âš ï¸ No products found for query: '{query}'")
            return json.dumps({
                "products": [],
                "message": f"Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ÛŒ Ø¨Ø§ Ø¬Ø³ØªØ¬ÙˆÛŒ '{query}' Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."
            }, ensure_ascii=False)
        
        logger.debug(f"ğŸ“¦ Got {len(results)} products from search")
        
        # Load brand scores
        logger.debug("ğŸ“Š Loading brand scores...")
        brand_scores = get_brand_scores()
        logger.debug(f"âœ… Loaded {len(brand_scores)} brand scores")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ§® Ù…Ø­Ø§Ø³Ø¨Ù‡ value_score Ø¨Ø§ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ† intent
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.debug("ğŸ§® Calculating value scores...")
        for product in results:
            # Calculate final price with discount
            price = product['price']
            discount_percentage = product['discount_percentage']
            final_price = price - (price * discount_percentage / 100)
            
            # Get brand score (default to 0.5 if brand not found)
            brand_name = product['brand_name'] if product['brand_name'] else ""
            brand_score = brand_scores.get(brand_name, 0.5)
            
            # Normalize final_price (divide by 1000000 to scale it appropriately)
            normalized_price = final_price / 1000000
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ğŸ“ ÙØ±Ù…ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù value_score Ø¨Ø± Ø§Ø³Ø§Ø³ intent
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if intent == "find_cheapest":
                # ÙÙ‚Ø· Ù‚ÛŒÙ…Øª Ù…Ù‡Ù…Ù‡ - Ù‡Ø±Ú†ÛŒ Ø§Ø±Ø²Ø§Ù†â€ŒØªØ± Ø¨Ù‡ØªØ±
                value_score = (
                    -normalized_price * 2.0 +          # Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± = Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ØªØ±
                    product['similarity'] * 0.3 +      # ÛŒÚ©Ù… similarity
                    brand_score * 0.1                  # Ø¨Ø±Ù†Ø¯ Ú©Ù…ØªØ±ÛŒÙ† Ø§Ù‡Ù…ÛŒØª
                )
                
            elif intent == "find_high_quality":
                # Ú©ÛŒÙÛŒØª Ùˆ Ø¨Ø±Ù†Ø¯ Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù…Ù‡
                value_score = (
                    brand_score * 1.5 +                # Ø¨Ø±Ù†Ø¯ Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù…
                    product['similarity'] * 0.5 +      # Ø´Ø¨Ø§Ù‡Øª Ø¨Ù‡ query
                    (discount_percentage / 100) * 0.3 - # ØªØ®ÙÛŒÙ ÛŒÙ‡ Ù¾Ù„Ø§Ø³
                    normalized_price * 0.1             # Ù‚ÛŒÙ…Øª Ú©Ù…ØªØ±ÛŒÙ† Ø§Ù‡Ù…ÛŒØª
                )
                
            elif intent == "find_by_feature":
                # similarity Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù…Ù‡ Ú†ÙˆÙ† Ú©Ø§Ø±Ø¨Ø± ÙˆÛŒÚ˜Ú¯ÛŒ Ø®Ø§ØµÛŒ Ù…ÛŒØ®ÙˆØ§Ø¯
                value_score = (
                    product['similarity'] * 1.5 +      # Ø´Ø¨Ø§Ù‡Øª Ø¨Ù‡ query Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù…
                    brand_score * quality_sensitivity * 0.4 +
                    (discount_percentage / 100) * 0.2 -
                    normalized_price * price_sensitivity * 0.3
                )
                
            elif intent == "compare":
                # Ù‡Ù…Ù‡ ÙØ§Ú©ØªÙˆØ±Ù‡Ø§ ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ Ø¨Ø±Ø§Ø¨Ø± - Ø¨Ø±Ø§ÛŒ ØªÙ†ÙˆØ¹ Ù†ØªØ§ÛŒØ¬
                value_score = (
                    brand_score * 0.3 +
                    product['similarity'] * 0.4 +
                    (discount_percentage / 100) * 0.2 -
                    normalized_price * 0.3
                )
                
            else:  # find_best_value ÛŒØ§ default
                # ÙØ±Ù…ÙˆÙ„ Ø§ØµÙ„ÛŒ Ù…ØªÙˆØ§Ø²Ù†
                value_score = (
                    brand_score * quality_sensitivity +
                    product['similarity'] * 0.4 +
                    (discount_percentage / 100) * 0.2 -
                    normalized_price * price_sensitivity
                )
            
            # Add to product dict
            product['final_price'] = int(final_price)
            product['brand_score'] = round(brand_score, 3)
            product['value_score'] = round(value_score, 3)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ù†ØªØ§ÛŒØ¬ Ø¨Ø± Ø§Ø³Ø§Ø³ intent
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.debug("ğŸ”„ Reranking by value_score...")
        results.sort(key=lambda x: x['value_score'], reverse=True)
        
        # Ø­Ø¯Ø§Ù‚Ù„ 1 Ùˆ Ø­Ø¯Ø§Ú©Ø«Ø± 5 Ù…Ø­ØµÙˆÙ„ Ø¨Ø±Ú¯Ø±Ø¯ÙˆÙ†
        MIN_RESULTS = 1
        MAX_RESULTS = 5
        
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ similarity Ø®ÛŒÙ„ÛŒ Ù¾Ø§ÛŒÛŒÙ† (Ø¨ÛŒâ€ŒØ±Ø¨Ø·)
        RELEVANCE_THRESHOLD = 0.4
        relevant_results = [r for r in results if r['similarity'] >= RELEVANCE_THRESHOLD]
        
        if not relevant_results:
            # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ Ù…Ø±ØªØ¨Ø·ÛŒ Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ù‡ØªØ±ÛŒÙ†â€ŒÙ‡Ø§ Ø±Ùˆ Ø¨Ø±Ú¯Ø±Ø¯ÙˆÙ† Ø¨Ø§ Ù‡Ø´Ø¯Ø§Ø±
            logger.warning(f"âš ï¸ No products above relevance threshold {RELEVANCE_THRESHOLD}")
            relevant_results = results[:MIN_RESULTS] if results else []
            is_relevant = False
        else:
            is_relevant = True
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± 5 Ù…Ø­ØµÙˆÙ„
        results = relevant_results[:MAX_RESULTS]
        
        logger.info(f"âœ… Returning {len(results)} products (min={MIN_RESULTS}, max={MAX_RESULTS}, relevant={is_relevant})")
        if results:
            logger.debug(f"ğŸ† Top product: {results[0]['product_name']} (value_score={results[0]['value_score']:.3f}, similarity={results[0]['similarity']:.3f})")
        
        # Format results as JSON
        products = []
        for product in results:
            products.append({
                "name": product['product_name'],
                "price": int(product['price']),
                "final_price": product['final_price'],
                "brand": product['brand_name'] if product['brand_name'] else "",
                "brand_score": product['brand_score'],
                "discount": int(product['discount_percentage']) if product['has_discount'] else 0,
                "product_id": str(product['product_id']),
                "similarity": round(product['similarity'], 3),
                "value_score": product['value_score'],
                "category": product['category_name'] if product['category_name'] else ""
            })
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ Ù‚ÛŒÙ…Øª
        if products:
            prices = [p['final_price'] for p in products]
            min_price = min(prices)
            max_price = max(prices)
            avg_similarity = sum(p['similarity'] for p in products) / len(products)
        else:
            min_price = max_price = 0
            avg_similarity = 0
        
        logger.info(f"ğŸ“¤ Returning {len(products)} products (price range: {min_price}-{max_price})")
        
        return json.dumps({
            "products": products,
            "meta": {
                "query": query,
                "total_found": len(products),
                "is_relevant": is_relevant,
                "avg_similarity": round(avg_similarity, 3),
                "price_range": {
                    "min": min_price,
                    "max": max_price
                },
                "intent": intent
            }
        }, ensure_ascii=False)
        
    except Exception as e:
        logger.error(f"âŒ Error in search_products_semantic: {str(e)}", exc_info=True)
        return json.dumps({
            "products": [],
            "error": "Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
        }, ensure_ascii=False)

